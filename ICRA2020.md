## ICRA 2020 IEEE International Conference on Robotics and Automation 

### 机器人视觉6D姿态估计论文

#### ICRA2020 6-PACK: Category-level 6D Pose Tracker with Anchor-Based Keypoints

* 标题：基于锚点关键点的类别级6D姿态跟踪
* 作者团队：斯坦福大学 & 上海交通大学 & 英伟达

我们提出了6-PACK，这是一种对RGB-D数据进行类别级目标6D姿态跟踪的深度学习方法。 我们的方法实时跟踪已知对象类别的新颖对象实例，例如碗，笔记本电脑和杯子。 6-PACK学会了通过几个3D关键点来紧凑地表示一个对象，基于这些3D关键点，可以通过关键点匹配来估计对象实例的帧间运动。 这些关键点是在没有人工监督的情况下端到端地学习的，以便最有效地进行跟踪。 我们的实验表明，我们的方法在NOCS类别级别的6D姿态估计基准上明显优于现有方法，并支持物理机器人执行基于视觉的简单闭环操纵任务。

[[arXiv]](https://arxiv.org/abs/2003.00188) | [[GitHub]](https://github.com/j96w/6-PACK)
***

#### ICRA2020 Self-supervised 6D Object Pose Estimation for Robot Manipulation

* 标题：用于机器人操纵的自监督6D物体姿态估计
* 作者团队：英伟达 & 伊利诺伊大学 & 华盛顿大学

如果要教机器人技能，就需要在监督下获取用于训练的数据。 由于标注现实世界的数据既费时又昂贵，因此使机器人能够以自我监督的方式进行学习非常重要。 在这项工作中，我们介绍了一种用于自我监督6D对象姿态估计的机器人系统。 从经过模拟训练的模块开始，我们的系统能够使用精确的6D对象姿态标记真实世界的数据，以进行自我监督学习。 另外，机器人与环境中的对象进行交互以通过抓取或推动对象来更改对象状态。 通过这种方式，我们的系统能够连续收集数据并改善其姿态估计模块。 我们证明了自我监督学习可以提高对象分割和6D姿势估计性能，从而使系统更可靠地抓取目标对象。

[[arXiv]](https://arxiv.org/abs/2004.06468)
***

#### ICRA2020 Robust 6D Object Pose Estimation by Learning RGB-D Features

* 标题：通过学习RGB-D功能进行可靠的6D对象姿态估计
* 作者团队：新加坡国立大学

准确的6D对象姿态估计对于机器人的操纵和抓握至关重要。 先前的方法大部分遵循局部优化，该方法将最近的点对之间的距离最小化以处理对称对象的旋转歧义。 在这项工作中，我们提出了一种新颖的离散连续公式用于旋转回归，以解决该局部最优问题。 我们 SO（3）中均匀采样旋转锚点，并预测从每个锚点到目标的约束偏差，以及用于选择最佳预测的不确定性分数。 另外，通过聚集指向3D中心的逐点向量来检测对象位置。在LINEMOD 和 YCB-Video 这两个基准数据集上进行的实验表明，该方法优于最新方法。

[[arXiv]](https://arxiv.org/abs/2003.00188) | [[GitHub]](https://github.com/mentian/object-posenet)
***

### ICRA 2020机器人领域顶级会议部分获奖*候选*论文如下：

* __大会最佳及机制与设计类最佳论文__：Design and Control of Roller Grasper V2 for In-Hand Manipulation 
  * [作者团队]：斯坦福大学（一作：上海交大本科毕业生）
  * [论文链接]：https://ras.papercept.net/proceedings/ICRA20/1733.pdf


* __大会最佳及人机交互类最佳论文__：Preference-Based Learning for Exoskeleton Gait Optimization

  * [作者团队]：加州理工学院&清华大学
  * [论文链接]：https://arxiv.org/pdf/1909.12316.pdf


* __大会最佳论文__：Prediction of Human Full-Body Movements with Motion Optimization and Recurrent Neural Networks

  * [作者团队]：斯图加特大学&蒂宾根大学
  * [论文链接]：https://arxiv.org/abs/1910.01843


* __机器人操纵类最佳论文__：6-DOF Grasping for Target-driven Object Manipulation in Clutter

  * [作者团队]：英伟达 (NVIDIA)&卡耐基梅隆大学&华盛顿大学
  * [论文链接]：https://arxiv.org/pdf/1912.03628.pdf


* __自动化类最佳论文__：Form2Fit: Learning Shape Priors for Generalizable Assembly from Disassembly

  * [作者团队]：斯坦福大学&谷歌&哥伦比亚大学
  * [论文链接]：https://arxiv.org/pdf/1910.13675.pdf


* __自动化类最佳论文__：Securing Industrial Operators with Collaborative Robots: Simulation and Experimental Validation for a Carpentry task

  * [作者团队]：IMS实验室（波尔多大学&法国国家科研究中心& UMR 5218）
  * [论文链接]：https://hal.inria.fr/hal-02418739v2/document



* __认知机器人类最佳论文__：Semantic Linking Maps for Active Visual Object Search

  * [作者团队]：密歇根大学&不莱梅大学
  * [论文链接]：[https://7948cefb-1ef7-4c55-96df-fcb8d527c697.filesusr.com/ugd/0886ee_198d7d01f879448bbf00733b21bfcbe9.pdf](https://link.zhihu.com/?target=https%3A//7948cefb-1ef7-4c55-96df-fcb8d527c697.filesusr.com/ugd/0886ee_198d7d01f879448bbf00733b21bfcbe9.pdf)



* __医疗机器人类最佳论文__：Fault Tolerant Control in Shape-Changing Internal Robots

  * [作者团队]：谢菲尔德大学
  * [论文链接]：http://eprints.whiterose.ac.uk/160367/



* __机器人视觉类最佳论文__：Graduated Non-Convexity for Robust Spatial Perception: From Non-Minimal Solvers to Global Outlier Rejection

  * [作者团队]：MIT&剑桥大学
  * [论文链接]：[https://arxiv.org/abs/1909.08605](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1909.08605)



* __无人机类最佳论文__：Design and Autonomous Stabilization of a Ballistically Launched Multirotor

  * [作者团队]：加州理工学院
  * [论文链接]：[https://arxiv.org/abs/1911.10269](
